{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets profile and check on the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U datasets accelerate transformers sentence-transformers mlflow psutil pynvml\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "# We need to install this extension to the base env\n",
    "/databricks/python/bin/pip3 install torch_tb_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "db_catalog = 'brian_ml_dev'\n",
    "db_schema = 'embedding_training'\n",
    "db_data_volume = 'datasets'\n",
    "db_volume = 'training_cache'\n",
    "\n",
    "browser_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "db_host = f\"https://{browser_host}\"\n",
    "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "os.environ['DATABRICKS_HOST'] = db_host\n",
    "os.environ['DATABRICKS_TOKEN'] = db_token\n",
    "\n",
    "experiment_id = 1715231020254790\n",
    "experiment_path = '/Users/brian.law@databricks.com/finetuning_embeddings'\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "os.environ['MLFLOW_EXPERIMENT_ID'] = f'{experiment_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Profiling we will use a separate train script that has profiling correctly configured\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.torch.distributor import TorchDistributor\n",
    "\n",
    "# num processes is the number of gpus that we want to use\n",
    "distributor = TorchDistributor(num_processes=1, \n",
    "                               local_mode=True, use_gpu=True)\n",
    "\n",
    "args = {\"--per_device_batch_size=256\",\n",
    "        \"--epochs=1\",\n",
    "        f\"--output_dir=/Volumes/{db_catalog}/{db_schema}/{db_volume}\"}\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    os.environ['MLFLOW_RUN_ID'] = run_id\n",
    "    os.environ['MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING'] = 'true'\n",
    "\n",
    "    train_obj = distributor.run('scripts/profile_train.py', *args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
